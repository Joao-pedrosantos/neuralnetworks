# Laboratory Exercises

This section contains hands-on exercises designed to reinforce theoretical concepts through practical implementation. Each exercise builds upon previous knowledge and introduces new concepts progressively.

## Exercise Structure

All exercises are provided as interactive Jupyter notebooks with:

- üìù **Detailed explanations** of concepts and methodology
- üíª **Starter code** with clear instructions
- üìä **Visualizations** to understand data and results
- ‚ùì **Questions** to test your understanding
- üéØ **Challenges** for deeper exploration

## Available Exercises

### Exercise 1: Data Generation and Visualization

This foundational exercise explores data generation, visualization, and the fundamental concept of class separability. The exercise is divided into three progressive parts:

!!! info "Exercise 1 Components"
    **Part A**: Basic data generation and visualization  
    **Part B**: Exploring different separation scenarios  
    **Part C**: Advanced separability analysis  

**Skills you'll develop:**
- Synthetic data generation using Gaussian distributions
- 2D data visualization techniques  
- Understanding linear and non-linear separability
- Statistical analysis of class distributions

**Notebooks:**
- [:material-notebook: Part A - Notebook](https://nbviewer.org/github/joao-pedrosantos/neuralnetworks/blob/main/exercises/exercise1.ipynb){ .md-button }
- [:material-notebook: Part B - Notebook](https://nbviewer.org/github/joao-pedrosantos/neuralnetworks/blob/main/exercises/exercise2.ipynb){ .md-button }  
- [:material-notebook: Part C - Notebook](https://nbviewer.org/github/joao-pedrosantos/neuralnetworks/blob/main/exercises/exercise3.ipynb){ .md-button }

[View Exercise 1 Details ‚Üí](exercise1/part-a.md){ .md-button .md-button--primary }

---

### Exercise 2: Perceptron

Build neural networks from scratch, understanding every component from forward propagation to backpropagation.

**Topics covered:**
- Forward and backward propagation
- Gradient computation and optimization
- Loss functions and performance metrics
- Network architecture design


---

### Exercise 3: Advanced Neural Networks (Coming Soon)

Explore advanced architectures and modern techniques used in deep learning.

**Topics covered:**
- Deep neural networks
- Regularization techniques
- Advanced optimization algorithms
- Model evaluation and selection

*This exercise will be available soon.*

## Getting Started

### Prerequisites
- Python 3.8+ installed
- Jupyter Notebook or JupyterLab
- Required packages (see requirements.txt)

### Setup Instructions

1. **Clone the repository**:
   ```bash
   git clone https://github.com/joao-pedrosantos/neuralnetworks.git
   cd neuralnetworks
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Launch Jupyter**:
   ```bash
   jupyter notebook exercises/
   ```

4. **Open any exercise notebook** and start learning!

## Tips for Success

!!! tip "Best Practices"
    - **Read thoroughly**: Don't skip the explanatory text in notebooks
    - **Experiment**: Try modifying parameters and observe results
    - **Visualize**: Use plots to understand what's happening with your data
    - **Document**: Add your own notes and observations
    - **Practice**: Complete all questions and challenges

!!! warning "Common Pitfalls"
    - Rushing through without understanding concepts
    - Not experimenting with different parameter values
    - Ignoring visualizations and their insights
    - Skipping the theoretical background sections

## Support and Resources

- üîß **Setup Issues**: Check [Tools & Setup](../resources/setup.md) for troubleshooting
- ‚ùì **Questions**: See [FAQ](../resources/faq.md) for common questions
- üí¨ **Discussion**: Use GitHub Issues for questions and discussion
